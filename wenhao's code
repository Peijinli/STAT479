library(dplyr)
library(stringr)
library(tidytext)
library(wordcloud)

tweet = read.csv("gun.tweets.csv",stringsAsFactors = FALSE)
tidy_tweet = tweet_select %>% unnest_tokens(word,text)  

tweet_select = tweet %>% select(text,favorite_count,retweet_count)%>%
  filter(!str_detect(text,'<U'))

tweet_select = cbind(tweet_select,c(1:nrow(tweet_select)))
colnames(tweet_select)[4] = "TweetIndex"

tidy_tweet %>%
  anti_join(stop_words) %>%
  count(word) %>%
  with(wordcloud(word, n, max.words = 100))

bing_word_counts <- tidy_tweet %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()
bing_word_counts

bing_word_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()
  
austen_bigrams <- tweet_select %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

wordvector = tweet_select %>%
  mutate(fcount=favorite_count+retweet_count,sort = TRUE)

library(tidyr)
bigrams_separated <- austen_bigrams %>%
  separate(bigram, c("word1", "word2"), sep = " ")

useless = c("twitter","https","iphone","android","rt","client")

bigrams_filtered <- bigrams_separated %>%
  filter(!word1 %in% c(stop_words$word,useless)) %>%
  filter(!word2 %in% c(stop_words$word,useless))

# new bigram counts:
bigram_counts = bigrams_filtered %>% 
  count(word1, word2, sort = TRUE)

bigram_counts
head(bigram_counts,30)



