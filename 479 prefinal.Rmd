---
title: "479 Project"
author: "Zhengyun Dou"
date: "4/19/2018"
output: html_document
---

```{r,ewarning=F,message=F,results='hide'}
#list of required packages
library(devtools)
library(rvest)
library(tidyverse)
library(stringr)
library(quantmod) #financial package
library(twitteR) #twitter from R
library(rtweet)
library(base64enc) #supplementary package to the above
library(lubridate)
library(tidytext)
library(widyr)
library(igraph)
library(ggraph)
library(tm)
library(wordcloud)
library(wordcloud2)
library(Matrix)
library(rARPACK)
library(data.table)
library(tidyr)
library(sunburstR)
```

```{r}
data=tibble(company=c("American Outdoor Brands","Sturm, Ruger","Vista Outdoor","Olin"),
            symbol=c("AOBC","RGR","VSTO","OLN"),
            agency=c("NASDAQ","NYSE","NYSE","NYSE"))

getSymbols(data$symbol,from="2017-01-01",adjust=TRUE) #all the four companies  
stock=Cl(get(data$symbol[1])) #close column of AOBC
for(i in 2:length(data$symbol))
  stock=merge(stock,Cl(get(data$symbol[i]))) #closure stock price for all four companies     
colnames(stock)=data$symbol
# tail(stock)
stockchange=stock%>% diff
#head(stockchange)

plot(as.zoo(stockchange), screens = 1, lty = 1:3, xlab = "Date", ylab = "Difference")
legend("topleft", c("AOBC", "RGR", "VSTO","OLN"), lty = 1:3, cex = 0.5)
```

```{r}
mass=read_csv("Mother Jones' Investigation_ US Mass Shootings, 1982-2018 - US mass shootings.csv")
# from https://www.motherjones.com/politics/2012/12/mass-shootings-mother-jones-full-data/
# str(mass)
# head(mass)
mass2017=mass %>% 
  mutate(Date=mdy(mass$Date)) %>% 
  filter(Date>="2017-01-01") #covert the date to be the same format as in stock[]

mdays=function(a,x){
  day=matrix(nrow = x,ncol=length(a))
  for (i in 1:x){
    day[i,]=a+i}
  c(a,day)}
#create a function to extend the mass shooting date to the following x days

daterange1=mdays(mass2017$Date,7)
case=rep(1:14,c(6,6,6,2,5,6,5,6,3,6,5,5,5,6)) %>% as.tibble()

variance=stock[daterange1] %>% as.tibble() %>% 
  mutate(date=index(stock[daterange1])) %>%
  cbind(.,case) %>% rename(shootingcase=value) %>% 
  group_by(shootingcase) %>% 
  summarise(varianceAOBC=var(AOBC),varianceRGR=var(RGR),
            varianceVSTO=var(VSTO),varianceOLN=var(OLN)) %>% 
  mutate(date=sort(mass2017$Date)) %>% select(shootingcase,date,varianceAOBC:varianceOLN)

variance

stock$VSTO[mdays(ymd("2017-01-06"),7)]
stock$VSTO[mdays(ymd("2017-11-05"),7)]

stock[daterange1] %>% as.tibble() %>% 
  mutate(date=index(stock[daterange1])) %>%cbind(.,case) %>%  
  gather('AOBC','RGR','VSTO','OLN',key="Co",value="price") %>% 
  ggplot(aes(y=price,x=date))+
  geom_point()+
  facet_grid(Co~value)

stock%>% diff %>% .[mdays(ymd("2017-01-06"),7)]
stock%>% diff %>% .[mdays(ymd("2017-11-05"),7)]
```

```{r}
twitters=fread("gun_twitters.csv") %>% as.tibble()
#dim(twitters)
#head(twitters)

stop_words=rbind(stop_words,c("rt",""))
twitters$text=str_replace_all(twitters$text,"http[s].*","")
cleaned=twitters  %>% 
  select(text) %>% 
  unnest_tokens(word,text) %>% 
  anti_join(stop_words)

frequency=cleaned %>% 
  count(word,sort=TRUE) 

frequency %>% top_n(15)

wordcloud2(frequency,figPath = "gunman.jpg",size=10)
```


```{r}
cleaned_two=twitters%>% 
  select(text) %>% 
  unnest_tokens(words,text,token="ngrams",n=2) 

separated=cleaned_two %>% 
  separate(words,c("word1","word2"),sep=" ")

filtered=separated %>% 
  filter(!word1 %in% stop_words$word) %>% 
  filter(!word2 %in% stop_words$word) %>% 
  count(word1,word2,sort=TRUE)

#head(filtered)

filtered %>% filter(n>20) %>% 
  graph_from_data_frame() %>% 
  ggraph(layout="fr")+
  geom_edge_link(aes(edge_alpha=n,edge_width=n))+
  geom_node_point(color = "gray", size = 3) +
  geom_node_text(aes(label = name), vjust = 1.8, size = 3)

```

